{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación con K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar NumPy para las operaciones con matrices y Matplotlib para generar algunas gráficas. Para mostrar las gráficas \n",
    "en el notebook Jupyter se importa también la función display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En machine learning tan importante como el algoritmo que hayamos decidido usar son los datos con los que lo vamos a alimentar. \n",
    "En este caso vamos a fabricarlos de forma aleatoria. El código anterior genera cincuenta muestras \n",
    "(o puntos o ejemplos, como prefieras) pero he hecho un poco de trampa. Se han creado alrededor de dos puntos distantes para que\n",
    "visualmente queden bien diferenciados. Para mantener la generalidad en todo momento he etiquetado con el valor 0 los puntos \n",
    "pertenecientes a la primera clase y con 1 los de la segunda. Una vez tenemos los datos los ponemos en una matriz de NumPy \n",
    "para poder operar con ellos. Finalmente mostramos la gráfica con los puntos, en azul los de la clase 0 y en verde los de la \n",
    "clase 1. Este es el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50 # 50 muestras aleatorias\n",
    "# generamos dos centros para las dos clases de puntos para entrenamiento \n",
    "c1 = [random.randint(0,1000), random.randint(0,1000)]\n",
    "c2 = [random.randint(0,1000), random.randint(0,1000)]\n",
    "# generamos las muestras aleatorias alrededor de los centros\n",
    "tuplasC1 = []\n",
    "tuplasC2 = []\n",
    "labelsC1 = []\n",
    "labelsC2 = []\n",
    "for i in range(int(n/2)):\n",
    "    tuplasC1.append([c1[0] + random.randint(-100,100), c1[1] + random.randint(-100,100)])\n",
    "    labelsC1.append(0)\n",
    "    tuplasC2.append([c2[0] + random.randint(-100,100), c2[1] + random.randint(-100,100)])\n",
    "    labelsC2.append(1)\n",
    "\n",
    "labels = labelsC1 + labelsC2\n",
    "puntos = np.matrix(tuplasC1 + tuplasC2)\n",
    "# dibujamos los puntos\n",
    "plt.scatter([puntos[:int(n/2),0]], [puntos[:int(n/2),1]], c=\"b\")\n",
    "plt.scatter([puntos[int(n/2):,0]], [puntos[int(n/2):,1]], c=\"g\")\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesitamos datos nuevos, es decir, aquellos que queremos clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos puntos aleatorios nuevos para clasificarlos\n",
    "n_test = 10\n",
    "tuplas = []\n",
    "for i in range(n_test):\n",
    "    tuplas.append([random.randint(0,1000), random.randint(0,1000)])\n",
    "    \n",
    "puntos_test = np.matrix(tuplas)\n",
    "# dibujamos los nuevos puntos junto con los anteriores\n",
    "plt.scatter([puntos[:int(n/2),0]], [puntos[:int(n/2),1]], c=\"b\")\n",
    "plt.scatter([puntos[int(n/2):,0]], [puntos[int(n/2):,1]], c=\"g\")\n",
    "plt.scatter([puntos_test[:,0]], [puntos_test[:,1]], c='r', marker='x')\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos diez puntos nuevos de forma totalmente aleatoria y mostramos la gráfica para ver por donde han caído (se muestran como X de color rojo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usamos KNN para clasificar los nuevos puntos\n",
    "k = 5 # número de vecinos\n",
    "\n",
    "pred_label = []\n",
    "# clasificamos cada uno de los puntos nuevos\n",
    "for i in range(puntos_test.shape[0]):\n",
    "    distances = []\n",
    "    # por cada punto calculamos la distancia con los puntos de entrenamiento \n",
    "    for j in range(puntos.shape[0]):\n",
    "        dist = np.sqrt(np.sum(np.square(puntos[j] - puntos_test[i])))\n",
    "        distances.append((dist, labels[j])) # guardamos las etiquetas y la distancia\n",
    "\n",
    "    # ordenamos por distancia y nos quedamos con los k vecinos más cercanos\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = distances[:k]\n",
    "    # contamos los votos para ver qué etiqueta gana\n",
    "    votes = [0,0]\n",
    "    for neighbor in neighbors:\n",
    "        votes[neighbor[1]] = votes[neighbor[1]] + 1\n",
    "    # obtenemos la etiqueta ganadora\n",
    "    pred_label.append(votes.index(max(votes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer bucle i va recorriendo la matriz de los puntos a etiquetar (recuerda que eran 10) y en el bucle interno j los \n",
    "comparamos con cada uno de los ejemplos o puntos del dataset de entrenamiento (recuerda que eran 50). Como ves no hay mucho \n",
    "misterio: calculamos la distancia entre ambos puntos operando matricialmente con NumPy y almacenamos dicha distancia junto \n",
    "a la clase (etiqueta) a la que pertenece el punto con el que estamos comparando. Una vez hemos medido todas las distancias \n",
    "las ordenamos y nos quedamos con las k menores (en este caso k=5). Ahora necesitamos saber a qué clases pertenecen \n",
    "los k vecinos más cercanos. Como hemos almacenado su etiqueta junto con la distancia, sometemos la decisión a un proceso de votación. \n",
    "Cada uno de los k vecinos vota con su etiqueta y la ganadora se asigna al nuevo punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar los datos clasificados para dibujarlos\n",
    "g0 = []\n",
    "g1 = []\n",
    "for i in range(len(pred_label)):\n",
    "    if pred_label[i] == 0:\n",
    "        g0.append([puntos_test[i,0], puntos_test[i,1]])\n",
    "    else:\n",
    "        g1.append([puntos_test[i,0], puntos_test[i,1]])\n",
    "        \n",
    "grupo0 = np.matrix(g0)\n",
    "grupo1 = np.matrix(g1)\n",
    "\n",
    "# mostrar datos ya clasificados\n",
    "plt.scatter([puntos[:int(n/2),0]], [puntos[:int(n/2),1]], c=\"b\")\n",
    "plt.scatter([puntos[int(n/2):,0]], [puntos[int(n/2):,1]], c=\"g\")\n",
    "plt.scatter([grupo0[:,0]], [grupo0[:,1]], c='b', marker='x')\n",
    "plt.scatter([grupo1[:,0]], [grupo1[:,1]], c='g', marker='x')\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos clasificados los nuevos puntos los metemos en una matriz simplemente para representarlos en una gráfica, junto \n",
    "con el color definitivo que le corresponde según han sido clasificados por k-nn. De esta forma comprobamos visualmente si \n",
    "la clasificación ha ido según lo esperado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
